{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How transfer learning works:\n",
    "<b>Part 1:</b> Train the Backbone\n",
    "1. Train a CNN (for example Resnet) on a large scale dataset like ImageNet where it learns how to create useful feature maps.\n",
    "    - This reduces image dimensions and increases the number of channels\n",
    "2. Do some pooling on the feature maps, then flatten and input into fully connected layers that predict the 1000 categories of ImageNet\n",
    "\n",
    "<b>Part 2:</b> Use Backbone to form final model.\n",
    "1. Get rid of the last layer that predicts the 1000 categories of ImageNet and instead make the output just the number of neurons you need.\n",
    "2. You can freeze the weights of the convolutional layers, if you do then this is called the feature extraction method.\n",
    "3. Retrain on your data so the final fully connected layers improve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode, damn didnt even know this existed\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Techniques\n",
    "\n",
    "- transforms.RandomResizedCrop(224):\n",
    "    - New image is a random crop of original image of size 224x224\n",
    "- transforms.RandomHorizontalFlip():\n",
    "    - Image is transformed with a horizontal flip 50% of the time\n",
    "- transforms.toTensor():\n",
    "    - Just converts the 3 channel image into a Tensor\n",
    "- transforms.Normalize():\n",
    "    - 2 main Benifits:\n",
    "        - Zero-Centering: Subtracting the mean of the pixel values makes the mean of the data approximately zero. This helps ensure that the network doesn't learn spurious biases based on the overall brightness or color of the images in the dataset.\n",
    "        - Scaling: Dividing by the standard deviation scales the pixel values, making them have a roughly consistent magnitude. This can help the training process converge faster and be more numerically stable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406]) # mean of imagenet dataset\n",
    "std = np.array([0.229, 0.224, 0.225])  # std of imagenet dataset\n",
    "\n",
    "dataTransforms = {\n",
    "    'train': \n",
    "        transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),          # crop image to 224x224\n",
    "        transforms.RandomHorizontalFlip(),          # flip image horizontally\n",
    "        transforms.ToTensor(),                      # convert image to tensor\n",
    "        transforms.Normalize(mean, std)]),          # normalize image\n",
    "        \n",
    "    'val': \n",
    "        transforms.Compose([\n",
    "        transforms.Resize(256),                     # resize image to 256x256\n",
    "        transforms.CenterCrop(224),                 # crop image to 224x224\n",
    "        transforms.ToTensor(),                      # convert image to tensor\n",
    "        transforms.Normalize(mean, std)]),          # normalize image\n",
    "    \n",
    "    'test': \n",
    "        transforms.Compose([\n",
    "        transforms.Resize(256),                     # resize image to 256x256\n",
    "        transforms.CenterCrop(224),                 # crop image to 224x224\n",
    "        transforms.ToTensor(),                      # convert image to tensor\n",
    "        transforms.Normalize(mean, std)]),          # normalize image\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 600\n",
      "    Root location: dataset\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dataset'\n",
    "sets = ['train', 'val', 'test']\n",
    "\n",
    "Image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), dataTransforms[x]) for x in sets} # create datasets\n",
    "\n",
    "print(Image_datasets['train']) # Check if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
